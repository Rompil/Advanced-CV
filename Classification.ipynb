{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1K3lfcaNQVVUQT12JIFh8AohEMXQHx9PG",
      "authorship_tag": "ABX9TyOKb5z4oa1raamimzheVnJX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rompil/Advanced-CV/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF2Ct0EjAe3I"
      },
      "source": [
        "! gdown --id 1VSIMAR3-2fXTEy-QdY2d0M_-aC1aXfWp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLiW98WVBpLX"
      },
      "source": [
        "!unzip -q Classification_data.zip\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBhGQ7leB-yu"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W32Ndh2tUZAm"
      },
      "source": [
        "image_size = (150, 150)\r\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9IgtXpwCA8V"
      },
      "source": [
        "\r\n",
        "\r\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    \"Classification_data/train\",\r\n",
        "    seed=1337,\r\n",
        "    image_size=image_size,\r\n",
        "    batch_size=batch_size,\r\n",
        ")\r\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    \"Classification_data/test\",\r\n",
        "    seed=1337,\r\n",
        "    image_size=image_size,\r\n",
        "    batch_size=batch_size,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN4HIal8exaj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM2jU8PuD7BE"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "for images, labels in train_ds.take(1):\r\n",
        "    for i in range(9):\r\n",
        "        ax = plt.subplot(3, 3, i + 1)\r\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n",
        "        plt.title(int(labels[i]))\r\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsOQwgVTEPqZ"
      },
      "source": [
        "data_augmentation = keras.Sequential(\r\n",
        "    [\r\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn873jn2Fzit"
      },
      "source": [
        "train_ds = train_ds.prefetch(buffer_size=32)\r\n",
        "val_ds = val_ds.prefetch(buffer_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IE4nmuavOyA"
      },
      "source": [
        "def make_simple_model(input_shape, num_classes):\r\n",
        "    inputs=keras.Input(shape=input_shape)\r\n",
        "    # Image augmentation block\r\n",
        "    x = data_augmentation(inputs)\r\n",
        "    x = layers.experimental.preprocessing.Rescaling(1.0/255)(x)\r\n",
        "    x = layers.Conv2D(32, 3,  padding=\"same\")(x)\r\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "    x = layers.Flatten()(x)\r\n",
        "    x = layers.Dense(100, activation=\"relu\")(x)\r\n",
        "    x = layers.Dropout(0.2)(x)\r\n",
        "\r\n",
        "    activation = \"softmax\"\r\n",
        "    units = num_classes\r\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\r\n",
        "    return keras.Model(inputs, outputs)\r\n",
        "model = make_simple_model(input_shape=image_size + (3,), num_classes=6)\r\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGGdoGBZiG3a"
      },
      "source": [
        "epochs = 23\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Colab Notebooks/models/simple_save_at_{epoch}.h5\"),\r\n",
        "]\r\n",
        "model.compile(\r\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\r\n",
        "    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "    metrics=[\"accuracy\"],\r\n",
        ")\r\n",
        "model.fit(\r\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo7dc8w9GQfV"
      },
      "source": [
        "def make_advanced_model(input_shape, num_classes):\r\n",
        "    inputs = keras.Input(shape=input_shape)\r\n",
        "    # Image augmentation block\r\n",
        "    x = data_augmentation(inputs)\r\n",
        "\r\n",
        "    # Entry block\r\n",
        "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\r\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    previous_block_activation = x  # Set aside residual\r\n",
        "\r\n",
        "    for size in [128, 256, 512, 728]:\r\n",
        "        x = layers.Activation(\"relu\")(x)\r\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\r\n",
        "        x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "        x = layers.Activation(\"relu\")(x)\r\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\r\n",
        "        x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\r\n",
        "\r\n",
        "        # Project residual\r\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\r\n",
        "            previous_block_activation\r\n",
        "        )\r\n",
        "        x = layers.add([x, residual])  # Add back residual\r\n",
        "        previous_block_activation = x  # Set aside next residual\r\n",
        "\r\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "\r\n",
        "    activation = \"softmax\"\r\n",
        "    units = num_classes\r\n",
        "\r\n",
        "    x = layers.Dropout(0.5)(x)\r\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\r\n",
        "    return keras.Model(inputs, outputs)\r\n",
        "\r\n",
        "\r\n",
        "model = make_advanced_model(input_shape=image_size + (3,), num_classes=6)\r\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crk7VCjUHQKY"
      },
      "source": [
        "epochs = 50\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Colab Notebooks/models/advanced_save_at_{epoch}.h5\"),\r\n",
        "]\r\n",
        "model.compile(\r\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\r\n",
        "    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "    metrics=[\"accuracy\"],\r\n",
        ")\r\n",
        "model.fit(\r\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqnbHCZpL0-Z"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5iGvmTwcyh5"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/models/final_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKXbX2Vt-Udp"
      },
      "source": [
        "img = keras.preprocessing.image.load_img(\n",
        "    \"/content/Classification_data/test/sea/20072.jpg\", target_size=image_size\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "model.load()\n",
        "predictions = model.predict(img_array)\n",
        "score = predictions[0]\n",
        "print(\n",
        "    predictions\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht2BkZVIPGqi"
      },
      "source": [
        "VGG16 as a base architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx80OwPzPLgm"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "vgg = VGG16(include_top=False, weights='imagenet', input_shape=list(image_size) + [3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF9y5_TFUjaP"
      },
      "source": [
        "# freeze some layers\r\n",
        "for layer in vgg.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3udjmGhV6y8"
      },
      "source": [
        "# new layers\r\n",
        "x = layers.Flatten()(vgg.output)\r\n",
        "x = layers.Dense(1000, activation='relu')(x)\r\n",
        "prediction = layers.Dense(6, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmZMBip8V9RL"
      },
      "source": [
        "# create a model object\r\n",
        "model = keras.models.Model(inputs=vgg.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "094WzekhrSVl"
      },
      "source": [
        "x = np.concatenate([x for x, y in val_ds], axis=0)\r\n",
        "y = np.concatenate([y for x, y in val_ds], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX_rLnaYjzWM"
      },
      "source": [
        " def is_correct_prediction(prediction, true_value):\r\n",
        "     print(np.argmax(prediction).shape)\r\n",
        "     print(true_value.shape)\r\n",
        "     return true_value == np.argmax(prediction)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "prediction = model.predict(x)\r\n",
        "arg_max = np.argmax(prediction, axis=1)\r\n",
        "(arg_max == y)\r\n",
        "# print(prediction.shape)\r\n",
        "# is_correct_prediction(model.predict(x), y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hB-DCFbqt7k"
      },
      "source": [
        "np.sum(arg_max == y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SQ7N7akXb78"
      },
      "source": [
        "def top5_best(x, y, model):\r\n",
        "    prediction = model.predict(x)\r\n",
        "    match = []\r\n",
        "    mismatch = []\r\n",
        "    print(is_correct_prediction(prediction, y))\r\n",
        "\r\n",
        "x = np.concatenate([x for x, y in val_ds], axis=0)\r\n",
        "y = np.concatenate([y for x, y in val_ds], axis=0)\r\n",
        "top5_best(x, y, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaSOD_rJZQr5"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTjz_xsJbYPe"
      },
      "source": [
        "x = np.concatenate([x for x, y in val_ds], axis=0)\r\n",
        "y = np.concatenate([y for x, y in val_ds], axis=0)\r\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbVn7Y6xdehX"
      },
      "source": [
        "\r\n",
        "x = [(model.predict(x[0]), y) for x, y in train_ds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ZPWe3geJ6Z"
      },
      "source": [
        "x = [x for x, _ in val_ds]\r\n",
        "model.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}