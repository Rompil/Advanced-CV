{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1K3lfcaNQVVUQT12JIFh8AohEMXQHx9PG",
      "authorship_tag": "ABX9TyOIOkNQjGkbrsjo7yuvfsid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rompil/Advanced-CV/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF2Ct0EjAe3I"
      },
      "source": [
        "! gdown --id 1VSIMAR3-2fXTEy-QdY2d0M_-aC1aXfWp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLiW98WVBpLX"
      },
      "source": [
        "!unzip -q Classification_data.zip\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBhGQ7leB-yu"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9IgtXpwCA8V"
      },
      "source": [
        "image_size = (150, 150)\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    \"Classification_data/train\",\r\n",
        "    seed=1337,\r\n",
        "    image_size=image_size,\r\n",
        "    batch_size=batch_size,\r\n",
        ")\r\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    \"Classification_data/test\",\r\n",
        "    seed=1337,\r\n",
        "    image_size=image_size,\r\n",
        "    batch_size=batch_size,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM2jU8PuD7BE"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "for images, labels in train_ds.take(1):\r\n",
        "    for i in range(9):\r\n",
        "        ax = plt.subplot(3, 3, i + 1)\r\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n",
        "        plt.title(int(labels[i]))\r\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsOQwgVTEPqZ"
      },
      "source": [
        "data_augmentation = keras.Sequential(\r\n",
        "    [\r\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCb_FYqdEnVB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn873jn2Fzit"
      },
      "source": [
        "train_ds = train_ds.prefetch(buffer_size=32)\r\n",
        "val_ds = val_ds.prefetch(buffer_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo7dc8w9GQfV"
      },
      "source": [
        "def make_model(input_shape, num_classes):\r\n",
        "    inputs = keras.Input(shape=input_shape)\r\n",
        "    # Image augmentation block\r\n",
        "    x = data_augmentation(inputs)\r\n",
        "\r\n",
        "    # Entry block\r\n",
        "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\r\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    previous_block_activation = x  # Set aside residual\r\n",
        "\r\n",
        "    for size in [128, 256, 512, 728]:\r\n",
        "        x = layers.Activation(\"relu\")(x)\r\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\r\n",
        "        x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "        x = layers.Activation(\"relu\")(x)\r\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\r\n",
        "        x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\r\n",
        "\r\n",
        "        # Project residual\r\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\r\n",
        "            previous_block_activation\r\n",
        "        )\r\n",
        "        x = layers.add([x, residual])  # Add back residual\r\n",
        "        previous_block_activation = x  # Set aside next residual\r\n",
        "\r\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Activation(\"relu\")(x)\r\n",
        "\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    if num_classes == 2:\r\n",
        "        activation = \"sigmoid\"\r\n",
        "        units = 1\r\n",
        "    else:\r\n",
        "        activation = \"softmax\"\r\n",
        "        units = num_classes\r\n",
        "\r\n",
        "    x = layers.Dropout(0.5)(x)\r\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\r\n",
        "    return keras.Model(inputs, outputs)\r\n",
        "\r\n",
        "\r\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=6)\r\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crk7VCjUHQKY"
      },
      "source": [
        "epochs = 50\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Colab Notebooks/models/save_at_{epoch}.h5\"),\r\n",
        "]\r\n",
        "model.compile(\r\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\r\n",
        "    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "    metrics=[\"accuracy\"],\r\n",
        ")\r\n",
        "model.fit(\r\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqnbHCZpL0-Z"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}